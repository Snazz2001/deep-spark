/*
 * Copyright 2014, Stratio.
 * 
 * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except
 * in compliance with the License. You may obtain a copy of the License at
 * 
 * http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing, software distributed under the License
 * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 * or implied. See the License for the specific language governing permissions and limitations under
 * the License.
 */

package com.stratio.deep.context;


import java.util.Map;

import org.apache.log4j.Logger;
import org.apache.spark.SparkContext;
import org.apache.spark.api.java.JavaSparkContext;

/**
 * Entry point to the Cassandra-aware Spark context.
 * 
 * @author Luca Rosellini <luca@stratio.com>
 */
public abstract class DeepSparkContext<T> extends JavaSparkContext {

  private static final Logger LOG = Logger.getLogger(DeepSparkContext.class);

  /**
   * Overridden superclass constructor.
   * 
   * @param sc an already created spark context.
   */
  DeepSparkContext(SparkContext sc) {
    super(sc);
  }

  /**
   * Overridden superclass constructor.
   * 
   * @param master the url of the master node.
   * @param appName the name of the application.
   */
  DeepSparkContext(String master, String appName) {
    super(master, appName);
  }

  /**
   * Overridden superclass constructor.
   * 
   * @param master the url of the master node.
   * @param appName the name of the application.
   * @param sparkHome the spark home folder.
   * @param jarFile the jar file to serialize and send to all the cluster nodes.
   */
  DeepSparkContext(String master, String appName, String sparkHome, String jarFile) {
    super(master, appName, sparkHome, jarFile);
  }

  /**
   * Overridden superclass constructor.
   * 
   * @param master the url of the master node.
   * @param appName the name of the application.
   * @param sparkHome the spark home folder.
   * @param jars the jar file(s) to serialize and send to all the cluster nodes.
   */
  DeepSparkContext(String master, String appName, String sparkHome, String[] jars) {
    super(master, appName, sparkHome, jars);
  }

  /**
   * Overridden superclass constructor.
   * 
   * @param master the url of the master node.
   * @param appName the name of the application.
   * @param sparkHome the spark home folder.
   * @param jars the jar file(s) to serialize and send to all the cluster nodes.
   * @param environment a map of environment variables.
   */
  DeepSparkContext(String master, String appName, String sparkHome, String[] jars,
      Map<String, String> environment) {
    super(master, appName, sparkHome, jars, environment);
  }

  // /**
  // * Builds a new JavaRDD.
  // *
  // * @param config the deep configuration object to use to create the new RDD.
  // * @return a new JavaRDD
  // */
  // @SuppressWarnings({"unchecked", "rawtypes"})
  // public <T> JavaRDD<T> createJavaRDD(IDeepJobConfig<T> config) {
  // return new JavaRDD<>(cassandraRDD(config));
  // }
  //
  // /**
  // * Builds a new generic Cassandra RDD.
  // *
  // * @param config the deep configuration object to use to create the new RDD.
  // * @return a new generic CassandraRDD.
  // */
  // @SuppressWarnings("unchecked")
  // public <T> RDD<T> createRDD(IDeepJobConfig<T> config) {
  // if (config.getClass().isAssignableFrom(EntityDeepJobConfig.class)) {
  // return new CassandraEntityRDD(sc(), config);
  // }
  //
  // if (config.getClass().isAssignableFrom(CellDeepJobConfig.class)) {
  // return (RDD<T>) new CassandraCellRDD(sc(),
  // (IDeepJobConfig<com.stratio.deep.entity.Cells>) config);
  // }
  //
  // throw new DeepGenericException("not recognized config type");
  //
  // }
}
